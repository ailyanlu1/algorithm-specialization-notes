WEBVTT

1
00:00:00.000 --> 00:00:04.608
In this video, we'll begin the proof of
the master method. The master method,

2
00:00:04.608 --> 00:00:09.585
you'll recall, is a generic solution to
recurrences of the given form, recurrences

3
00:00:09.585 --> 00:00:14.563
in which there's a recursive calls, each
on a sub-problem of the same size, size n

4
00:00:14.563 --> 00:00:19.602
over b, assuming that the original problem
had size n. And, plus, there is big O of n

5
00:00:19.602 --> 00:00:24.210
to the d work done by the algorithm
outside of these a recursive calls. The

6
00:00:24.210 --> 00:00:28.880
solution that the master method provides
has three cases, depending on how a

7
00:00:28.880 --> 00:00:33.293
compares to b to the d. Now. This proof
will be the longest one we've seen so far

8
00:00:33.293 --> 00:00:37.341
by a significant margin. It'll span this
video as well as the next two. So let me

9
00:00:37.341 --> 00:00:41.093
say a few words up front about what you
might want to focus on. Overall I think

10
00:00:41.093 --> 00:00:44.986
the proof is quite conceptual. There's a
couple of spots where we're going to have

11
00:00:44.986 --> 00:00:48.548
to do some computations. And the
computations I think are worth seeing once

12
00:00:48.548 --> 00:00:52.157
in your life. I don't know that they're
worth really committing to long term

13
00:00:52.157 --> 00:00:55.576
memory. What I do think is worth
remembering in the long term however, is

14
00:00:55.576 --> 00:00:59.422
the conceptual meaning of the three cases
of the master method. In particular the

15
00:00:59.422 --> 00:01:03.221
proof will follow a recursionary approach
just like we used in the running time

16
00:01:03.221 --> 00:01:07.020
analysis of the Mertshot algorithm. And it
worth remembering what three types of

17
00:01:07.020 --> 00:01:10.928
recursion trees the three cases Is that
the master method corresponds to. If you

18
00:01:10.928 --> 00:01:14.412
can remember that, there will be
absolutely no need to memorize any of

19
00:01:14.412 --> 00:01:18.343
these three running times, including the
third, rather exotic looking one. Rather,

20
00:01:18.343 --> 00:01:22.374
you'll be able to reverse engineer those
running times just from your conceptual

21
00:01:22.374 --> 00:01:26.654
understanding of what the three cases mean
and how they correspond to recursion trees

22
00:01:26.654 --> 00:01:30.563
of different type. So, one final comment
before we embark on the proof. So, as

23
00:01:30.563 --> 00:01:34.265
usual, I'm uninterested in formality in
its own sake. The reason we use

24
00:01:34.265 --> 00:01:38.389
mathematical analysis in this course, is
because it provides an explanation of,

25
00:01:38.389 --> 00:01:42.619
fundamentally, why things are the way they
are. For example, why the master method

26
00:01:42.619 --> 00:01:46.480
has three cases, and what those three
cases mean. So, I'll be giving you an

27
00:01:46.480 --> 00:01:50.710
essentially complete proof of the master
method, in the sense that it has all of

28
00:01:50.710 --> 00:01:55.046
the key ingredients. I will cut corners on
occasion, where I don't think it hinders

29
00:01:55.046 --> 00:01:58.853
understanding, where it's easy to fill in
the details. So, it won't be 100 percent

30
00:01:58.853 --> 00:02:02.873
rigorous, I won't dot every I and cross
every t, but. There will be a complete

31
00:02:02.873 --> 00:02:07.216
proof, on the conceptual level. That being
said, let me begin with a couple of minor

32
00:02:07.216 --> 00:02:11.332
assumptions I"m going to make, to make our
lives a little easier. So first, we're

33
00:02:11.332 --> 00:02:15.592
gonna assume that the recurrence has the
following form. So, here, essentially, all

34
00:02:15.592 --> 00:02:18.952
I've done is I've taken our previous
assumption about the format of a

35
00:02:18.952 --> 00:02:22.696
recurrence, and I've written out all of
the constants. So, I'm assuming that the

36
00:02:22.696 --> 00:02:26.632
base case kicks in when the input size is
one, and I'm assuming that the number of

37
00:02:26.632 --> 00:02:30.569
operations in the base case is at most c,
and that, that constant c is the same one

38
00:02:30.569 --> 00:02:34.409
that was hidden in the big O notation of
the general case of the recurrence. The

39
00:02:34.409 --> 00:02:38.297
constant c here isn't gonna matter in the
analysis, it's just all gonna be a wash,

40
00:02:38.297 --> 00:02:41.993
but to make, keep everything clear, I'm
gonna write out all the constants that

41
00:02:41.993 --> 00:02:45.689
were previously hidden in the big O
notation. Another assumption I'm going to

42
00:02:45.689 --> 00:02:50.538
make. Now goes to our murtured analysis,
is that N is a power of B. The general

43
00:02:50.538 --> 00:02:54.649
case would be basically the same, just a
little more tedious. At the highest level,

44
00:02:54.649 --> 00:02:58.505
the proof of the master method should
strike you as very natural. Really, all

45
00:02:58.505 --> 00:03:02.362
we're going to do is revisit the way that
we analyze Merge Short. Recall our

46
00:03:02.362 --> 00:03:06.421
recursion tree method worked great, and
gave us this [inaudible] log [inaudible],

47
00:03:06.421 --> 00:03:10.329
and the running time of Merge Short. So
we're just gonna mimic that recursion

48
00:03:10.329 --> 00:03:14.413
tree, and see how far we get. So let me
remind you what a recursion tree is. At

49
00:03:14.413 --> 00:03:18.544
the roots, at level zero, we have the
outermost, the initial indication of the

50
00:03:18.544 --> 00:03:22.837
recursive algorithm. At level one, we have
the first batch of recursive calls. At

51
00:03:22.837 --> 00:03:26.968
level two, we have the recursive calls
made by that first batch of recursive

52
00:03:26.968 --> 00:03:31.262
calls, and so on. All the way down to the
leaves of the tree, which correspond to

53
00:03:31.262 --> 00:03:35.795
the base cases, where there's no further
recursion. Now, you might recall, from the

54
00:03:35.795 --> 00:03:40.818
Merge Sort analysis that we identified a
pattern that was crucial in analyzing the

55
00:03:40.818 --> 00:03:45.841
running time. And that pattern that we had
to understand was, at a given [inaudible]

56
00:03:45.841 --> 00:03:50.379
J, at a given level J of this recursion
tree. First of all, how many distinct

57
00:03:50.379 --> 00:03:55.342
subproblems are there at level J? How many
different level J [inaudible] are there?

58
00:03:55.342 --> 00:04:00.304
And secondly, what is the input size that
each of those level J subproblems has to

59
00:04:00.304 --> 00:04:04.781
operate on? So think about that a little
bit and give your answer in the following

60
00:04:04.781 --> 00:04:10.649
quiz. So the correct answer is the second
one. At level J at. Of this recursion

61
00:04:10.649 --> 00:04:14.645
tree, there are A to, to the J
sub-problems and each has an input of size

62
00:04:14.645 --> 00:04:19.085
of N over B to the J. So first of all, why
are there A to the J sub-problems? Well,

63
00:04:19.085 --> 00:04:23.137
when J equals zero at the root, there's
just the one problem, the original

64
00:04:23.137 --> 00:04:27.918
indication of the recursive algorithm. And
then each. Call to the algorithm makes a

65
00:04:27.918 --> 00:04:32.643
further calls. For that reason the number
of sub problems goes up by a factor of A

66
00:04:32.643 --> 00:04:37.080
with each level leading to A to the J sub
problems at level J. Similarly, B is

67
00:04:37.080 --> 00:04:41.921
exactly the factor by which the input size
shrinks once you makea recursive call. So

68
00:04:41.921 --> 00:04:46.589
J levels into the recursion. The input
size has been shrunk J times by a fctor of

69
00:04:46.589 --> 00:04:51.083
B each time. So the input size at level J
is N over B to the J. That's also the

70
00:04:51.083 --> 00:04:55.751
reason why, if you look at the question
statement, we've identified the numbers of

71
00:04:55.751 --> 00:05:00.863
levels as being log of base B. Of N. Back
in Merge Short, B was two. We [inaudible]

72
00:05:00.863 --> 00:05:05.870
on half the array. So the leaves all
resided at level log base two of N. In

73
00:05:05.870 --> 00:05:11.351
general, if we're dividing by a factor B
each time, then it takes a log based B of

74
00:05:11.351 --> 00:05:16.832
N times before we get down the base cases
of size of one. So the number of levels

75
00:05:16.832 --> 00:05:22.246
overall, zero through log base B event.
For a total of log based B event plus one

76
00:05:22.246 --> 00:05:28.525
levels. Here then is what the recursion
tree looks like. At level zero we have the

77
00:05:28.525 --> 00:05:34.933
root corresponding to the outer most call.
And the input size here is N. The original

78
00:05:34.933 --> 00:05:40.784
problem. Children of a node correspond to
the recursive calls. Because there are A.

79
00:05:40.784 --> 00:05:46.977
Recursive calls by assumption, there are
A. Children or A. Branches. Level one is

80
00:05:46.977 --> 00:05:54.590
the first batch of precursor calls. Each
of which operates on an input of size N

81
00:05:54.590 --> 00:06:00.344
over B. That level log base B. Of N. We've
cut the input size by a factor of B. This

82
00:06:00.344 --> 00:06:05.210
many times, so we're down to one. So that
triggers the base case. So now, the plan

83
00:06:05.210 --> 00:06:09.563
is to simply mimic our previous analysis
of Merge Sort. So let's recall how that

84
00:06:09.563 --> 00:06:13.862
worked. What we did is we zoomed in, in a
given level. And for a given level J, we

85
00:06:13.862 --> 00:06:18.379
counted the total amount of work that was
done at level J subproblems, not counting

86
00:06:18.379 --> 00:06:22.460
work that was gonna be done later by
recursive calls. Then, given a bound on

87
00:06:22.460 --> 00:06:26.704
the amount of work at a given level J, we
just summed up overall, the levels, to

88
00:06:26.704 --> 00:06:30.785
capture all of the work done by all of
the, recursive indications of the

89
00:06:30.785 --> 00:06:35.169
algorithm. So inspired by our previous
success let's zoom in on a given level J.,

90
00:06:35.169 --> 00:06:39.132
and see how much work gets done, with
level J. Sub problems. We're going to

91
00:06:39.132 --> 00:06:43.511
compute this in exactly the way we did in
merge sort. And we were just going to look

92
00:06:43.511 --> 00:06:47.630
at the number of problems that are at
level J and we're going to multiply that

93
00:06:47.630 --> 00:06:51.488
by a bound on the work done per
sub-problem. We just identified the number

94
00:06:51.488 --> 00:06:56.179
of level J sub-problems as A to the J. To
understand the amount of work done for

95
00:06:56.179 --> 00:07:01.211
each level j sub-problem, let's do it in
two parts. So, first of all, let's focus

96
00:07:01.211 --> 00:07:05.984
on the size of the input for each level j
sub-problem. That's what we just

97
00:07:05.984 --> 00:07:11.403
identified in the previous quiz question.
Since the input size is being decreased by

98
00:07:11.403 --> 00:07:16.500
a factor b each time, the size of each
level j sub-problem is n over b to the j.

99
00:07:16.500 --> 00:07:21.199
[inaudible] Now we only care about the
size of a level J sub problem in as much

100
00:07:21.199 --> 00:07:25.375
it determines the amount of work the
number of operations that we perform per

101
00:07:25.375 --> 00:07:29.871
level J sub problem. And to understand the
relationship between those two quantities

102
00:07:29.871 --> 00:07:34.153
we just return to the re currents. The
recurrent says how much work gets done in

103
00:07:34.153 --> 00:07:38.543
the specific sub problem well there's a
bunch of work done by recursive calls the

104
00:07:38.543 --> 00:07:42.825
A recursive calls and we're not counting
that we're just counting the work done

105
00:07:42.825 --> 00:07:47.268
here at A level J and the recurrence also
tells us how much is done outside of the

106
00:07:47.268 --> 00:07:51.390
recurrent calls. Namely it's no more than
the constant C times the input size.

107
00:07:51.390 --> 00:07:57.899
Raised to the d power. So here the input
size is N over B to the J, so that gets

108
00:07:57.899 --> 00:08:05.122
multiplied by the constant C. And it gets
raised to the D power. Okay. So C. Times

109
00:08:05.122 --> 00:08:11.311
quanity N. Over B. To the J. That's the
emphasized. Raised to the D. Power. Next,

110
00:08:11.311 --> 00:08:15.704
I wanna simplify this expression a little
bit. And I wanna separate out the terms

111
00:08:15.704 --> 00:08:19.934
which depend on the level number J, and
the terms which are independent of the

112
00:08:19.934 --> 00:08:24.490
level number J. So if you look at it A and
B are both functions of J, where the C and

113
00:08:24.490 --> 00:08:28.994
end of the D terms are independent of J.
So let's just separate those out. And you

114
00:08:28.994 --> 00:08:34.444
will notice that we have now our grand
entrance of the ratio between A and B to

115
00:08:34.444 --> 00:08:40.030
the D. And foreshadowing a little, recall
that the three cases of the master method

116
00:08:40.030 --> 00:08:45.820
are governed by the relationship between A
and B to the D. And this is the first time

117
00:08:45.820 --> 00:08:51.066
in the analysis where we get a clue that
the relative magnitude of those two

118
00:08:51.066 --> 00:08:56.038
quantities might be important. So now that
we've zoomed in on a particular label J

119
00:08:56.038 --> 00:09:00.487
and done the necessary computation to
figure out how much work is done just at

120
00:09:00.487 --> 00:09:04.936
that level, let's sum over all of the
levels so that we capture all of the work

121
00:09:04.936 --> 00:09:09.441
done by the algorithms. So this is just
gonna be the sum of the epression we saw

122
00:09:09.441 --> 00:09:14.002
on the previous slide. Now since C into
the D doesn't depend on J, I can yank that

123
00:09:14.002 --> 00:09:18.676
out in front of the sum, and I'll sum the
expression over all J. That results in the

124
00:09:18.676 --> 00:09:23.885
following. So believe it or not, we have
now reached an important milestone in the

125
00:09:23.885 --> 00:09:28.442
proof of the master method. Specifically,
the somewhat messy looking formula here,

126
00:09:28.442 --> 00:09:32.829
which I'll put a green box around, is
going to be crucial. And the rest of the

127
00:09:32.829 --> 00:09:37.159
proof will be devoted to interpreting and
understanding this expression, and

128
00:09:37.159 --> 00:09:41.888
understanding how it leads to the three
different running time bounds in the three

129
00:09:41.888 --> 00:09:46.345
different cases. Now I realize that at the
moment this expression's star probably

130
00:09:46.345 --> 00:09:50.655
just looks like alphabet soup, probably
just looks like a bunch of mathematical

131
00:09:50.655 --> 00:09:54.419
gibberish. But actually interpreted
correctly this has a very natural

132
00:09:54.419 --> 00:09:57.420
interpretation. So we'll discuss that in
the next video.